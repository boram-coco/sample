{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad244d08-663b-49cb-9da8-064cac1edfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "fde45f94-5caa-44dd-a63e-a8fb14487f79",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"CH4. 지도 그래프 학습(그래프 정규화 방법)\"\n",
    "author: \"김보람\"\n",
    "date: \"04/06/2023\"\n",
    "categories:\n",
    "  - graph\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c30aef6-13d6-4e62-a99a-3b6cb7e4c44e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a6bce-8de7-4744-a459-2cf6064ce796",
   "metadata": {
    "tags": []
   },
   "source": [
    "- [그래프 머신러닝](https://product.kyobobook.co.kr/detail/S000200738068)\n",
    "\n",
    "- [github](https://github.com/PacktPublishing/Graph-Machine-Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b2d7c5-f853-4745-933e-08038bfaa010",
   "metadata": {},
   "source": [
    "# 신경 그래프 학습(NGL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2940c877-c6b1-421c-9847-e208d03b1e85",
   "metadata": {},
   "source": [
    "- NGL(Neural Graph Learning)\n",
    "\n",
    "- 라벨 전파 및 라벨 확산 알고리즘의 비선형 버전..\n",
    "\n",
    "- [NLS 프레임워크](https://github.com/tensorflow/neural-structured-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42824b38-300f-4976-9868-1bf959b81695",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c3482b-e703-449e-abcc-4ede7399d07c",
   "metadata": {},
   "source": [
    "`-` 데이터셋: Cora\n",
    "\n",
    "- 7개의 클래스로 라벨링돼 있는 2,708개의 컴퓨터 사이언스 논문\n",
    "\n",
    "- 각 논문은 인용을 기반으로 다른 노드와 연결된 노드\n",
    "\n",
    "- 총 5,429개의 간선\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8142182d-e273-490a-82f0-4dc6c31756b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 21:44:50.486139: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from stellargraph import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c795f4f1-e2b1-4186-a65d-d798214f9062",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Cora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2640510-c9f8-4a80-99a7-1b2e7f4e2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ebf216-f9ed-4960-bb4c-78591065be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b285a65f-b685-4c8d-ba4f-ea0bd061e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = {\n",
    "      'Case_Based': 0,\n",
    "      'Genetic_Algorithms': 1,\n",
    "      'Neural_Networks': 2,\n",
    "      'Probabilistic_Methods': 3,\n",
    "      'Reinforcement_Learning': 4,\n",
    "      'Rule_Learning': 5,\n",
    "      'Theory': 6,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca68ae6-02cf-4194-979f-344297560449",
   "metadata": {},
   "outputs": [],
   "source": [
    "G, labels = dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d59492-235e-414b-99f8-694a87198530",
   "metadata": {},
   "source": [
    "- G: 네트워크 노드, 간선, BOW표현 설명\n",
    "\n",
    "- labea : 논문id와 클래스 중 하나 사이의 매핑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2b6c6-b7a2-4da8-badf-6add54c109aa",
   "metadata": {},
   "source": [
    "- 훈련 샘플: 이웃과 관련된 정보가 포함 -> 훈련을 정규화 하는데 사용\n",
    "\n",
    "- 검증 샘플: 이웃과 관련된 정보 불포함 , 예측된 라벨은 노드 특증, bow표현에만 의존"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c52d5f-3032-4e46-a4db-35815756b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, feature_extraction, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07c63b48-559b-4bd2-bba7-ae62076ef496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.train import Example, Features, Feature, Int64List, BytesList, FloatList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "152fa995-6805-4ea4-828d-2a4519e703b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH_PREFIX=\"NL_nbr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca071e6-12dc-4c17-b458-2c206c6cca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(*value):\n",
    "    \"\"\"Returns int64 tf.train.Feature from a bool / enum / int / uint.\"\"\"\n",
    "    return Feature(int64_list=Int64List(value=list(value)))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns bytes tf.train.Feature from a string.\"\"\"\n",
    "    return Feature(\n",
    "        bytes_list=BytesList(value=[value.encode('utf-8')])\n",
    "    )\n",
    "\n",
    "def _float_feature(*value):\n",
    "    return Feature(float_list=FloatList(value=list(value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958079d-1b05-40f5-8cf0-c0385e3f8722",
   "metadata": {},
   "source": [
    "- _int64_feature 함수는 bool, enum, int, uint 데이터 타입을 입력 받아 int64_list 타입의 tf.train.Feature 객체를 반환\n",
    "\n",
    "- _bytes_feature 함수는 문자열 값을 입력 받아 utf-8로 인코딩하여 bytes_list 타입의 tf.train.Feature 객체를 반환\n",
    "\n",
    "- _float_feature 함수는 float 데이터 타입을 입력 받아 float_list 타입의 tf.train.Feature 객체를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1a512-154e-4036-8acb-039dcbb74d57",
   "metadata": {},
   "source": [
    "`-` 반지도 학습 데이터 셋 만드는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd42f25-774b-41ed-af3a-ad10b067ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import six\n",
    "\n",
    "def addFeatures(x, y):\n",
    "    res = Features()\n",
    "    res.CopyFrom(x)\n",
    "    res.MergeFrom(y)\n",
    "    return res\n",
    "\n",
    "def neighborFeatures(features: Features, weight: float, prefix: str):  # 객체, 가중치, 접두어 입력으로 받음\n",
    "    data = {f\"{prefix}_weight\": _float_feature(weight)}\n",
    "    for name, feature in six.iteritems(features.feature):\n",
    "        data[f\"{prefix}_{name}\"] = feature \n",
    "    return Features(feature=data)\n",
    "\n",
    "def neighborsFeatures(neighbors: List[Tuple[Features, float]]):\n",
    "    return reduce(\n",
    "        addFeatures, \n",
    "        [neighborFeatures(sample, weight, f\"{GRAPH_PREFIX}_{ith}\") for ith, (sample, weight) in enumerate(neighbors)],\n",
    "        Features()\n",
    "    )\n",
    "\n",
    "def getNeighbors(idx, adjMatrix, topn=5): #인덱스와 인접행렬 이용하여 이웃 데이터셋 추출 \n",
    "    weights = adjMatrix.loc[idx]\n",
    "    return weights[weights>0].sort_values(ascending=False).head(topn).to_dict()\n",
    "    \n",
    "\n",
    "def semisupervisedDataset(G, labels, ratio=0.2, topn=5):  #라벨이 있는 데이터와 없는 데이터 추출\n",
    "     #ratio:라벨 유무 비율 설정\n",
    "     #topn: 함수에서 추출할 이웃 데이터셋 크기 설정\n",
    "    n = int(np.round(len(labels)*ratio)) \n",
    "    \n",
    "    labelled, unlabelled = model_selection.train_test_split(\n",
    "        labels, train_size=n, test_size=None, stratify=labels\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d5ec42-e0d6-4178-9810-c36b922ea87e",
   "metadata": {},
   "source": [
    "### 1. 노드 특징 df로 구성하고 그래프 인접행렬로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "522866ec-bd88-4129-9c16-e486e2f1d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjMatrix = pd.DataFrame.sparse.from_spmatrix(G.to_adjacency_matrix(), index=G.nodes(), columns=G.nodes())\n",
    "    \n",
    "features = pd.DataFrame(G.node_features(), index=G.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d39d60-36ab-4f61-abb2-9deb6dcf85e5",
   "metadata": {},
   "source": [
    "### 2. adjMatrix사용해 노드ID와 간선 가중치 반환하여 노드의 가장 가까운 TOPN이웃 검색하는 도우미 함수 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f7cab-8d99-44d6-af16-a482d140430f",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def getNeighbors(idx, adjMatrix, topn=5): #인덱스와 인접행렬 이용하여 이웃 데이터셋 추출 \n",
    "    weights = adjMatrix.loc[idx]\n",
    "    neighbors = weights[weights>0]\\\n",
    "        .sort_values(ascending=False)\\\n",
    "        .head(topn)\n",
    "    return [(k,v) for k, v in neighbors.iteritems()]\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05daa008-622f-496b-93f4-9e23635fd266",
   "metadata": {},
   "source": [
    "### 3. 정보를 단일 df로 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c6bf39c-08e9-4291-bc3c-c14eba48408c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labelled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m         index: Features(feature \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m             \u001b[38;5;66;03m#\"id\": _bytes_feature(str(index)), \u001b[39;00m\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: _int64_feature(index),\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m\"\u001b[39m: _float_feature(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mloc[index]\u001b[38;5;241m.\u001b[39mvalues]), \n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: _int64_feature(label_index[label])\n\u001b[1;32m      7\u001b[0m         })\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m index, label \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mlabelled\u001b[49m, unlabelled])\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m      9\u001b[0m     }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labelled' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "        index: Features(feature = {\n",
    "            #\"id\": _bytes_feature(str(index)), \n",
    "            \"id\": _int64_feature(index),\n",
    "            \"words\": _float_feature(*[float(x) for x in features.loc[index].values]), \n",
    "            \"label\": _int64_feature(label_index[label])\n",
    "        })\n",
    "        for index, label in pd.concat([labelled, unlabelled]).items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dff7312-71b6-4670-b015-59272d3e9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import six\n",
    "\n",
    "def addFeatures(x, y):\n",
    "    res = Features()\n",
    "    res.CopyFrom(x)\n",
    "    res.MergeFrom(y)\n",
    "    return res\n",
    "\n",
    "def neighborFeatures(features: Features, weight: float, prefix: str):\n",
    "    data = {f\"{prefix}_weight\": _float_feature(weight)}\n",
    "    for name, feature in six.iteritems(features.feature):\n",
    "        data[f\"{prefix}_{name}\"] = feature \n",
    "    return Features(feature=data)\n",
    "\n",
    "def neighborsFeatures(neighbors: List[Tuple[Features, float]]):\n",
    "    return reduce(\n",
    "        addFeatures, \n",
    "        [neighborFeatures(sample, weight, f\"{GRAPH_PREFIX}_{ith}\") for ith, (sample, weight) in enumerate(neighbors)],\n",
    "        Features()\n",
    "    )\n",
    "\n",
    "def getNeighbors(idx, adjMatrix, topn=5):\n",
    "    weights = adjMatrix.loc[idx]\n",
    "    return weights[weights>0].sort_values(ascending=False).head(topn).to_dict()\n",
    "    \n",
    "\n",
    "def semisupervisedDataset(G, labels, ratio=0.2, topn=5):\n",
    "    n = int(np.round(len(labels)*ratio))\n",
    "    \n",
    "    labelled, unlabelled = model_selection.train_test_split(\n",
    "        labels, train_size=n, test_size=None, stratify=labels\n",
    "    )\n",
    "    \n",
    "    adjMatrix = pd.DataFrame.sparse.from_spmatrix(G.to_adjacency_matrix(), index=G.nodes(), columns=G.nodes())\n",
    "    \n",
    "    features = pd.DataFrame(G.node_features(), index=G.nodes())\n",
    "    \n",
    "    dataset = {\n",
    "        index: Features(feature = {\n",
    "            #\"id\": _bytes_feature(str(index)), \n",
    "            \"id\": _int64_feature(index),\n",
    "            \"words\": _float_feature(*[float(x) for x in features.loc[index].values]), \n",
    "            \"label\": _int64_feature(label_index[label])\n",
    "        })\n",
    "        for index, label in pd.concat([labelled, unlabelled]).items()\n",
    "    }\n",
    "    \n",
    "    trainingSet = [\n",
    "        Example(features=addFeatures(\n",
    "            dataset[exampleId], \n",
    "            neighborsFeatures(\n",
    "                [(dataset[nodeId], weight) for nodeId, weight in getNeighbors(exampleId, adjMatrix, topn).items()]\n",
    "            )\n",
    "        ))\n",
    "        for exampleId in labelled.index\n",
    "    ]\n",
    "    \n",
    "    testSet = [Example(features=dataset[exampleId]) for exampleId in unlabelled.index]\n",
    "\n",
    "    serializer = lambda _list: [e.SerializeToString() for e in _list]\n",
    "    \n",
    "    return serializer(trainingSet), serializer(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0642d3-bfb9-4d0b-9dea-65680e5aae83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
